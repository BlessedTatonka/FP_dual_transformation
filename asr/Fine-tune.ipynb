{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-26 17:30:19 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.4.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2021-10-26 17:30:19 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.4.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2021-10-26 17:30:19 common:702] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-10-26 17:30:19 features:262] PADDING: 16\n",
      "[NeMo I 2021-10-26 17:30:19 features:279] STFT using torch\n",
      "[NeMo I 2021-10-26 17:30:20 save_restore_connector:143] Model EncDecCTCModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.4.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "import pathlib\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(\n",
    "    model_name=\"QuartzNet15x5Base-En\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = '../../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastwer\n",
    "\n",
    "def calculate_score(dataset, model, model_name='-', k=None, log=False):\n",
    "    print(f'Calculating score for model {model_name} on {dataset}')\n",
    "    if dataset == 'LJSpeech':\n",
    "        metadata = pd.read_csv(datasets_dir + 'LJSpeech-1.1/metadata_test.csv')\n",
    "        if k is not None:\n",
    "            metadata = metadata[:k]\n",
    "        files = metadata['file_name'].apply(lambda x: f'{datasets_dir}/LJSpeech-1.1/wavs/{x}.wav').values\n",
    "        texts = metadata['transcript'].values\n",
    "    elif dataset == 'AN4':\n",
    "        metadata = pd.read_csv(f'{datasets_dir}/an4/metadata.csv')\n",
    "        files = metadata['file_name'].values\n",
    "        texts = metadata['transcript'].values\n",
    "        \n",
    "    \n",
    "    wer = []\n",
    "    cer = []\n",
    "    predictions = model.transcribe(paths2audio_files=files)\n",
    "    r = np.random.randint(1, 100)\n",
    "    print(texts[r])\n",
    "    print(predictions[r])\n",
    "    for i in range(len(predictions)):\n",
    "        wer.append(fastwer.score_sent(texts[i].lower(), predictions[i], char_level=False))\n",
    "        cer.append(fastwer.score_sent(texts[i].lower(), predictions[i], char_level=True))\n",
    "\n",
    "    wer = np.array(wer)\n",
    "    cer = np.array(wer)\n",
    "    \n",
    "    wer = wer[wer != float('+inf')]\n",
    "    cer = wer[wer != float('+inf')]\n",
    "    \n",
    "    print(np.mean(wer))\n",
    "    wer = np.round(np.mean(wer), 2)\n",
    "    cer = np.round(np.mean(cer), 2)\n",
    "    if log:\n",
    "        print(f'wer:{np.round(wer, 2)}; cer:{np.round(cer, 2)}')\n",
    "    \n",
    "    return wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for model quartznet_15x5 on LJSpeech\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3f2ddfc87042d1b9d336e2e021de3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would see anything in the newspaper about his defection, unless he engaged in activities similar to those\n",
      "would see anything in the newspaper about his defection unless he engaged in activities similar to those\n",
      "17.392450999999998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17.39, 17.39)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score('LJSpeech', quartznet, 'quartznet_15x5', k=100)\n",
    "calculate_score('AN4', quartznet, 'quartznet_15x5', k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.utilities import rank_zero_info\n",
    "\n",
    "import copy\n",
    "\n",
    "class PrintTableMetricsCallback(Callback):\n",
    "    \"\"\"Prints a table with the metrics in columns on every epoch end.\n",
    "    Example::\n",
    "        from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "        callback = PrintTableMetricsCallback()\n",
    "    Pass into trainer like so:\n",
    "    .. code-block:: python\n",
    "        trainer = pl.Trainer(callbacks=[callback])\n",
    "        trainer.fit(...)\n",
    "        # ------------------------------\n",
    "        # at the end of every epoch it will print\n",
    "        # ------------------------------\n",
    "        # loss│train_loss│val_loss│epoch\n",
    "        # ──────────────────────────────\n",
    "        # 2.2541470527648926│2.2541470527648926│2.2158432006835938│0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.metrics: List = []\n",
    "\n",
    "    def on_epoch_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
    "        metrics_dict = copy.copy(trainer.callback_metrics)\n",
    "        self.metrics.append(metrics_dict)\n",
    "        rank_zero_info(dicts_to_table(self.metrics))\n",
    "        \n",
    "def dicts_to_table(\n",
    "    dicts: List[Dict],\n",
    "    keys: Optional[List[str]] = None,\n",
    "    pads: Optional[List[str]] = None,\n",
    "    fcodes: Optional[List[str]] = None,\n",
    "    convert_headers: Optional[Dict[str, Callable]] = None,\n",
    "    header_names: Optional[List[str]] = None,\n",
    "    skip_none_lines: bool = False,\n",
    "    replace_values: Optional[Dict[str, Any]] = None,\n",
    ") -> str:\n",
    "    \"\"\"Generate ascii table from dictionary Taken from (https://stackoverflow.com/questions/40056747/print-a-list-\n",
    "    of-dictionaries-in-table-form)\n",
    "    Args:\n",
    "        dicts: input dictionary list; empty lists make keys OR header_names mandatory\n",
    "        keys: order list of keys to generate columns for; no key/dict-key should\n",
    "            suffix with '____' else adjust code-suffix\n",
    "        pads: indicate padding direction and size, eg <10 to right pad alias left-align\n",
    "        fcodes: formating codes for respective column type, eg .3f\n",
    "        convert_headers: apply converters(dict) on column keys k, eg timestamps\n",
    "        header_names: supply for custom column headers instead of keys\n",
    "        skip_none_lines: skip line if contains None\n",
    "        replace_values: specify per column keys k a map from seen value to new value;\n",
    "                        new value must comply with the columns fcode; CAUTION: modifies input (due speed)\n",
    "    Example:\n",
    "        >>> a = {'a': 1, 'b': 2}\n",
    "        >>> b = {'a': 3, 'b': 4}\n",
    "        >>> print(dicts_to_table([a, b]))\n",
    "        a│b\n",
    "        ───\n",
    "        1│2\n",
    "        3│4\n",
    "    \"\"\"\n",
    "    # optional arg prelude\n",
    "    if keys is None:\n",
    "        if len(dicts) > 0:\n",
    "            keys = dicts[0].keys()  # type: ignore[assignment]\n",
    "        elif header_names is not None:\n",
    "            keys = header_names\n",
    "        else:\n",
    "            raise ValueError(\"keys or header_names mandatory on empty input list\")\n",
    "    if pads is None:\n",
    "        pads = [\"\"] * len(keys)  # type: ignore[arg-type]\n",
    "    elif len(pads) != len(keys):  # type: ignore[arg-type]\n",
    "        raise ValueError(f\"bad pad length {len(pads)}, expected: {len(keys)}\")  # type: ignore[arg-type]\n",
    "    if fcodes is None:\n",
    "        fcodes = [\"\"] * len(keys)  # type: ignore[arg-type]\n",
    "    elif len(fcodes) != len(fcodes):\n",
    "        raise ValueError(f\"bad fcodes length {len(fcodes)}, expected: {len(keys)}\")  # type: ignore[arg-type]\n",
    "    if convert_headers is None:\n",
    "        convert_headers = {}\n",
    "    if header_names is None:\n",
    "        header_names = keys\n",
    "    if replace_values is None:\n",
    "        replace_values = {}\n",
    "    # build header\n",
    "    headline = \"│\".join(f\"{v:{pad}}\" for v, pad in zip_longest(header_names, pads))  # type: ignore[arg-type]\n",
    "    underline = \"─\" * len(headline)\n",
    "    # suffix special keys to apply converters to later on\n",
    "    marked_keys = [h + \"____\" if h in convert_headers else h for h in keys]  # type: ignore[union-attr]\n",
    "    marked_values = {}\n",
    "    s = \"│\".join(f\"{{{h}:{pad}{fcode}}}\" for h, pad, fcode in zip_longest(marked_keys, pads, fcodes))\n",
    "    lines = [headline, underline]\n",
    "    for d in dicts:\n",
    "        none_keys = [k for k, v in d.items() if v is None]\n",
    "        if skip_none_lines and none_keys:\n",
    "            continue\n",
    "        elif replace_values:\n",
    "            for k in d.keys():\n",
    "                if k in replace_values and d[k] in replace_values[k]:\n",
    "                    d[k] = replace_values[k][d[k]]\n",
    "                if d[k] is None:\n",
    "                    raise ValueError(f\"bad or no mapping for key '{k}' is None. Use skip or change replace mapping.\")\n",
    "        elif none_keys:\n",
    "            raise ValueError(f\"keys {none_keys} are None in {d}. Do skip or use replace mapping.\")\n",
    "        for h in convert_headers:\n",
    "            if h in keys:  # type: ignore[operator]\n",
    "                converter = convert_headers[h]\n",
    "                marked_values[h + \"____\"] = converter(d)\n",
    "        line = s.format(**d, **marked_values)\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-26 17:30:39 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.4.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n",
      "[NeMo I 2021-10-26 17:30:39 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.4.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo\n",
      "[NeMo I 2021-10-26 17:30:39 common:702] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-10-26 17:30:40 features:262] PADDING: 16\n",
      "[NeMo I 2021-10-26 17:30:40 features:279] STFT using torch\n",
      "[NeMo I 2021-10-26 17:30:40 save_restore_connector:143] Model EncDecCTCModel was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.4.0/QuartzNet15x5Base-En/2b066be39e9294d7100fb176ec817722/QuartzNet15x5Base-En.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-26 17:30:40 audio_to_text_dataset:37] Model level config does not container `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
      "[NeMo I 2021-10-26 17:30:40 audio_to_text_dataset:37] Model level config does not container `labels`, please explicitly provide `labels` to the dataloaders.\n",
      "[NeMo I 2021-10-26 17:30:40 collections:173] Dataset loaded with 10480 files totalling 19.11 hours\n",
      "[NeMo I 2021-10-26 17:30:40 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2021-10-26 17:30:40 audio_to_text_dataset:37] Model level config does not container `sample_rate`, please explicitly provide `sample_rate` to the dataloaders.\n",
      "[NeMo I 2021-10-26 17:30:40 audio_to_text_dataset:37] Model level config does not container `labels`, please explicitly provide `labels` to the dataloaders.\n",
      "[NeMo I 2021-10-26 17:30:41 collections:173] Dataset loaded with 2620 files totalling 4.81 hours\n",
      "[NeMo I 2021-10-26 17:30:41 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2021-10-26 17:30:41 modelPT:544] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.95, 0.25]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2021-10-26 17:30:41 lr_scheduler:625] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fe0298a9cd0>\" \n",
      "    will be used during training (effective maximum steps = 26200) - \n",
      "    Parameters : \n",
      "    (last_epoch: -1\n",
      "    min_lr: 0.0\n",
      "    warmup_ratio: 0.12\n",
      "    warmup_steps: null\n",
      "    max_steps: 26200\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-10-26 17:30:41 modelPT:544] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.95, 0.25]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2021-10-26 17:30:41 lr_scheduler:625] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7fe029946410>\" \n",
      "    will be used during training (effective maximum steps = 26200) - \n",
      "    Parameters : \n",
      "    (last_epoch: -1\n",
      "    min_lr: 0.0\n",
      "    warmup_ratio: 0.12\n",
      "    warmup_steps: null\n",
      "    max_steps: 26200\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConvASREncoder                    | 18.9 M\n",
      "2 | decoder           | ConvASRDecoder                    | 29.7 K\n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | _wer              | WER                               | 0     \n",
      "------------------------------------------------------------------------\n",
      "18.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 M    Total params\n",
      "75.698    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss│val_wer\n",
      "────────────────\n",
      "103.06062316894531│0.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efece472989f4aa98248ff8b6bc66545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val_loss│val_wer\n",
      "────────────────\n",
      "103.06062316894531│0.125\n",
      "5.842962265014648│0.03738697990775108\n",
      "val_loss│val_wer\n",
      "────────────────\n",
      "103.06062316894531│0.125\n",
      "5.842962265014648│0.03738697990775108\n",
      "5.842962265014648│0.03738697990775108\n",
      "[NeMo W 2021-10-26 17:38:52 nemo_logging:349] /home/boris/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "      rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "import pathlib\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "quartznet = nemo_asr.models.EncDecCTCModel.from_pretrained(\n",
    "    model_name=\"QuartzNet15x5Base-En\"\n",
    ")\n",
    "\n",
    "train_manifest_file = \"../../datasets/LJSpeech-1.1/train_manifest.json\"\n",
    "val_manifest_file = \"../../datasets/LJSpeech-1.1/test_manifest.json\"\n",
    "\n",
    "callback = PrintTableMetricsCallback()\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=10, callbacks=[callback])\n",
    "\n",
    "\n",
    "new_opt = {\n",
    "    \"betas\": [0.8, 0.25],\n",
    "    \"lr\": 0.0001,\n",
    "    \"name\": \"novograd\",\n",
    "    \"sched\": {\n",
    "        \"last_epoch\": -1,\n",
    "        \"min_lr\": 0.0,\n",
    "        \"monitor\": \"val_loss\",\n",
    "        \"name\": \"CosineAnnealing\",\n",
    "        \"reduce_on_plateau\": False,\n",
    "        \"warmup_ratio\": 0.12,\n",
    "        \"warmup_steps\": None,\n",
    "    },\n",
    "    \"weight_decay\": 0.001,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "train_ds_config = {\n",
    "    \"batch_size\": 4,\n",
    "    \"is_tarred\": False,\n",
    "    \"num_workers\": 12,\n",
    "    \"pin_memory\": True,\n",
    "    \"labels\": [\n",
    "        \" \",\n",
    "        \"a\",\n",
    "        \"b\",\n",
    "        \"c\",\n",
    "        \"d\",\n",
    "        \"e\",\n",
    "        \"f\",\n",
    "        \"g\",\n",
    "        \"h\",\n",
    "        \"i\",\n",
    "        \"j\",\n",
    "        \"k\",\n",
    "        \"l\",\n",
    "        \"m\",\n",
    "        \"n\",\n",
    "        \"o\",\n",
    "        \"p\",\n",
    "        \"q\",\n",
    "        \"r\",\n",
    "        \"s\",\n",
    "        \"t\",\n",
    "        \"u\",\n",
    "        \"v\",\n",
    "        \"w\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"'\",\n",
    "    ],\n",
    "    \"manifest_filepath\": str(train_manifest_file),\n",
    "    \"max_duration\": 16.7,\n",
    "    \"sample_rate\": 16000,\n",
    "    \"shuffle\": True,\n",
    "    \"tarred_audio_filepaths\": None,\n",
    "    \"trim_silence\": True,\n",
    "}\n",
    "\n",
    "train_ds_config = DictConfig(train_ds_config)\n",
    "\n",
    "val_ds_config = {\n",
    "    \"batch_size\": 4,\n",
    "    \"num_workers\": 12,\n",
    "    \"pin_memory\": True,\n",
    "    \"labels\": [\n",
    "        \" \",\n",
    "        \"a\",\n",
    "        \"b\",\n",
    "        \"c\",\n",
    "        \"d\",\n",
    "        \"e\",\n",
    "        \"f\",\n",
    "        \"g\",\n",
    "        \"h\",\n",
    "        \"i\",\n",
    "        \"j\",\n",
    "        \"k\",\n",
    "        \"l\",\n",
    "        \"m\",\n",
    "        \"n\",\n",
    "        \"o\",\n",
    "        \"p\",\n",
    "        \"q\",\n",
    "        \"r\",\n",
    "        \"s\",\n",
    "        \"t\",\n",
    "        \"u\",\n",
    "        \"v\",\n",
    "        \"w\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"z\",\n",
    "        \"'\",\n",
    "    ],\n",
    "    \"manifest_filepath\": str(val_manifest_file),\n",
    "    \"sample_rate\": 16000,\n",
    "    \"shuffle\": False,\n",
    "}\n",
    "\n",
    "val_ds_config = DictConfig(val_ds_config)\n",
    "\n",
    "\n",
    "quartznet.setup_training_data(train_data_config=train_ds_config)\n",
    "quartznet.setup_validation_data(val_data_config=val_ds_config)\n",
    "quartznet.set_trainer(trainer)\n",
    "quartznet.setup_optimization(optim_config=DictConfig(new_opt))\n",
    "\n",
    "trainer.fit(quartznet)\n",
    "quartznet.save_to(\"test.nemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating score for model quartznet_15x5 on LJSpeech\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7629e0a3b8a74a758b664917fd3b2dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but there were no serious accidents, beyond those caused by the goring of a maddened, over-driven ox which forced its way through the crowd.\n",
      "but there were no serious accidents beyond those caused by the goring of a maddened overdriven ox which forced its way through the crowd\n",
      "17.392450999999998\n",
      "Calculating score for model quartznet_15x5 on AN4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ced1b4c16e4b1ba245dec735d87445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Transcribing:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter nine one six nine\n",
      "enter \n",
      "225.67828350515464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(225.68, 225.68)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_score('LJSpeech', quartznet, 'quartznet_15x5', k=100)\n",
    "calculate_score('AN4', quartznet, 'quartznet_15x5', k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartznet.save_to(\"test.nemo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../'\n",
    "datasets_dir = '../../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = quartznet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
