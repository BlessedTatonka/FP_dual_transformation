{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-11-06 00:13:34 optimizers:47] Apex was not found. Using the lamb optimizer will error out.\n",
      "[NeMo W 2021-11-06 00:13:34 nemo_logging:349] /home/boris/anaconda3/lib/python3.7/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[NeMo W 2021-11-06 00:13:35 nmse_clustering:54] Using eigen decomposition from scipy, upgrade torch to 1.9 or higher for faster clustering\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "[NeMo W 2021-11-06 00:13:35 nemo_logging:349] /home/boris/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "      '\"sox\" backend is being deprecated. '\n",
      "    \n",
      "[NeMo W 2021-11-06 00:13:35 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text_dali._AudioTextDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "import pathlib\n",
    "import nemo.collections.asr as nemo_asr\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir = '../../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fastwer\n",
    "\n",
    "def calculate_score(dataset, model, model_name='-', k=None, log=True):\n",
    "    print(f'Calculating score for model {model_name} on {dataset}')\n",
    "    if dataset == 'LJSpeech':\n",
    "        metadata = pd.read_csv(datasets_dir + 'LJSpeech-1.1/metadata_test.csv')\n",
    "        if k is not None:\n",
    "            metadata = metadata[:k]\n",
    "        files = metadata['file_name'].apply(lambda x: f'{datasets_dir}/LJSpeech-1.1/wavs/{x}.wav').values\n",
    "        texts = metadata['transcript'].values\n",
    "    elif dataset == 'AN4':\n",
    "        metadata = pd.read_csv(f'{datasets_dir}/an4/metadata.csv')\n",
    "        files = metadata['file_name'].values\n",
    "        texts = metadata['transcript'].values\n",
    "        \n",
    "    \n",
    "    wer = []\n",
    "    cer = []\n",
    "    predictions = model.transcribe(paths2audio_files=files)\n",
    "    r = np.random.randint(1, 10)\n",
    "    print(texts[r])\n",
    "    print(predictions[r].replace('⁇', ''))\n",
    "    for i in range(len(predictions)):\n",
    "        text = texts[i].lower()\n",
    "        text = re.sub('[^a-zA-Z ]+', '', text)\n",
    "        prediction = predictions[i]\n",
    "        prediction = re.sub('[^a-zA-Z ]+', '', prediction)\n",
    "        wer.append(fastwer.score_sent(text, prediction, char_level=False))\n",
    "        cer.append(fastwer.score_sent(text, prediction, char_level=True))\n",
    "    wer = np.array(wer)\n",
    "    cer = np.array(cer)\n",
    "    \n",
    "    wer = wer[wer != float('+inf')]\n",
    "    cer = cer[cer != float('+inf')]\n",
    "    \n",
    "    wer = np.round(np.mean(wer), 2)\n",
    "    cer = np.round(np.mean(cer), 2)\n",
    "    if log:\n",
    "        print(f'wer:{np.round(wer, 2)}; cer:{np.round(cer, 2)}')\n",
    "    \n",
    "    return wer, cer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.utilities import rank_zero_info\n",
    "\n",
    "import copy\n",
    "\n",
    "class PrintTableMetricsCallback(Callback):\n",
    "    \"\"\"Prints a table with the metrics in columns on every epoch end.\n",
    "    Example::\n",
    "        from pl_bolts.callbacks import PrintTableMetricsCallback\n",
    "        callback = PrintTableMetricsCallback()\n",
    "    Pass into trainer like so:\n",
    "    .. code-block:: python\n",
    "        trainer = pl.Trainer(callbacks=[callback])\n",
    "        trainer.fit(...)\n",
    "        # ------------------------------\n",
    "        # at the end of every epoch it will print\n",
    "        # ------------------------------\n",
    "        # loss│train_loss│val_loss│epoch\n",
    "        # ──────────────────────────────\n",
    "        # 2.2541470527648926│2.2541470527648926│2.2158432006835938│0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.metrics: List = []\n",
    "\n",
    "    def on_epoch_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
    "        metrics_dict = copy.copy(trainer.callback_metrics)\n",
    "        self.metrics.append(metrics_dict)\n",
    "        rank_zero_info(dicts_to_table(self.metrics))\n",
    "        \n",
    "def dicts_to_table(\n",
    "    dicts: List[Dict],\n",
    "    keys: Optional[List[str]] = None,\n",
    "    pads: Optional[List[str]] = None,\n",
    "    fcodes: Optional[List[str]] = None,\n",
    "    convert_headers: Optional[Dict[str, Callable]] = None,\n",
    "    header_names: Optional[List[str]] = None,\n",
    "    skip_none_lines: bool = False,\n",
    "    replace_values: Optional[Dict[str, Any]] = None,\n",
    ") -> str:\n",
    "    \"\"\"Generate ascii table from dictionary Taken from (https://stackoverflow.com/questions/40056747/print-a-list-\n",
    "    of-dictionaries-in-table-form)\n",
    "    Args:\n",
    "        dicts: input dictionary list; empty lists make keys OR header_names mandatory\n",
    "        keys: order list of keys to generate columns for; no key/dict-key should\n",
    "            suffix with '____' else adjust code-suffix\n",
    "        pads: indicate padding direction and size, eg <10 to right pad alias left-align\n",
    "        fcodes: formating codes for respective column type, eg .3f\n",
    "        convert_headers: apply converters(dict) on column keys k, eg timestamps\n",
    "        header_names: supply for custom column headers instead of keys\n",
    "        skip_none_lines: skip line if contains None\n",
    "        replace_values: specify per column keys k a map from seen value to new value;\n",
    "                        new value must comply with the columns fcode; CAUTION: modifies input (due speed)\n",
    "    Example:\n",
    "        >>> a = {'a': 1, 'b': 2}\n",
    "        >>> b = {'a': 3, 'b': 4}\n",
    "        >>> print(dicts_to_table([a, b]))\n",
    "        a│b\n",
    "        ───\n",
    "        1│2\n",
    "        3│4\n",
    "    \"\"\"\n",
    "    # optional arg prelude\n",
    "    if keys is None:\n",
    "        if len(dicts) > 0:\n",
    "            keys = dicts[0].keys()  # type: ignore[assignment]\n",
    "        elif header_names is not None:\n",
    "            keys = header_names\n",
    "        else:\n",
    "            raise ValueError(\"keys or header_names mandatory on empty input list\")\n",
    "    if pads is None:\n",
    "        pads = [\"\"] * len(keys)  # type: ignore[arg-type]\n",
    "    elif len(pads) != len(keys):  # type: ignore[arg-type]\n",
    "        raise ValueError(f\"bad pad length {len(pads)}, expected: {len(keys)}\")  # type: ignore[arg-type]\n",
    "    if fcodes is None:\n",
    "        fcodes = [\"\"] * len(keys)  # type: ignore[arg-type]\n",
    "    elif len(fcodes) != len(fcodes):\n",
    "        raise ValueError(f\"bad fcodes length {len(fcodes)}, expected: {len(keys)}\")  # type: ignore[arg-type]\n",
    "    if convert_headers is None:\n",
    "        convert_headers = {}\n",
    "    if header_names is None:\n",
    "        header_names = keys\n",
    "    if replace_values is None:\n",
    "        replace_values = {}\n",
    "    # build header\n",
    "    headline = \"│\".join(f\"{v:{pad}}\" for v, pad in zip_longest(header_names, pads))  # type: ignore[arg-type]\n",
    "    underline = \"─\" * len(headline)\n",
    "    # suffix special keys to apply converters to later on\n",
    "    marked_keys = [h + \"____\" if h in convert_headers else h for h in keys]  # type: ignore[union-attr]\n",
    "    marked_values = {}\n",
    "    s = \"│\".join(f\"{{{h}:{pad}{fcode}}}\" for h, pad, fcode in zip_longest(marked_keys, pads, fcodes))\n",
    "    lines = [headline, underline]\n",
    "    for d in dicts:\n",
    "        none_keys = [k for k, v in d.items() if v is None]\n",
    "        if skip_none_lines and none_keys:\n",
    "            continue\n",
    "        elif replace_values:\n",
    "            for k in d.keys():\n",
    "                if k in replace_values and d[k] in replace_values[k]:\n",
    "                    d[k] = replace_values[k][d[k]]\n",
    "                if d[k] is None:\n",
    "                    raise ValueError(f\"bad or no mapping for key '{k}' is None. Use skip or change replace mapping.\")\n",
    "        elif none_keys:\n",
    "            raise ValueError(f\"keys {none_keys} are None in {d}. Do skip or use replace mapping.\")\n",
    "        for h in convert_headers:\n",
    "            if h in keys:  # type: ignore[operator]\n",
    "                converter = convert_headers[h]\n",
    "                marked_values[h + \"____\"] = converter(d)\n",
    "        line = s.format(**d, **marked_values)\n",
    "        lines.append(line)\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from ruamel.yaml import YAML\n",
    "except ModuleNotFoundError:\n",
    "    from ruamel_yaml import YAML\n",
    "\n",
    "config_path = 'stt_en_citrinet_256_gamma_0_25'\n",
    "config_name = 'model_config.yaml'\n",
    "yaml = YAML(typ='safe')\n",
    "\n",
    "with open(os.path.join(config_path, config_name)) as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['tokenizer']['dir'] = 'citrinet_tokenizer/tokenizer_spe_unigram_v1024'\n",
    "config['tokenizer']['type'] = 'bpe'\n",
    "\n",
    "config['train_ds']['manifest_filepath']=\"../../datasets/LJSpeech-1.1/train_manifest.json\"\n",
    "config['train_ds']['batch_size'] = 1\n",
    "config['train_ds']['num_workers'] = 12\n",
    "config['train_ds']['pin_memory'] = True\n",
    "\n",
    "config['validation_ds']['manifest_filepath']=\"../../datasets/LJSpeech-1.1/test_manifest.json\"\n",
    "config['validation_ds']['batch_size'] = 1\n",
    "config['validation_ds']['num_workers'] = 12\n",
    "config['validation_ds']['pin_memory'] = True\n",
    "\n",
    "config['spec_augment']['freq_masks'] = 0\n",
    "config['spec_augment']['time_masks'] = 0\n",
    "config['optim']['lr'] = 0.01\n",
    "config['optim']['name'] = 'novograd'\n",
    "config['optim']['betas'] = [0.8, 0.25]\n",
    "config['optim']['weight_decay'] = 0.001\n",
    "config['optim']['sched']['warmup_steps']=1000\n",
    "config['optim']['sched']['min_lr'] = 0.00001\n",
    "\n",
    "config['tokenizer']['model_path'] = 'stt_en_citrinet_256_gamma_0_25/3d20ebb793c84a64a20c7ad26fc64d62_tokenizer.model'\n",
    "config['tokenizer']['vocab_path'] = 'stt_en_citrinet_256_gamma_0_25/df5191f216004f10a268c44e90fdb63f_vocab.txt'\n",
    "config['tokenizer']['spe_tokenizer_vocab'] = 'stt_en_citrinet_256_gamma_0_25/b774eaac83804907843607272fde21a4_tokenizer.vocab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-11-06 00:15:06 cloud:56] Found existing object /home/boris/.cache/torch/NeMo/NeMo_1.4.0/stt_en_citrinet_256_gamma_0_25/d6eff3868f2f7a4791eb935c8366fc46/stt_en_citrinet_256_gamma_0_25.nemo.\n",
      "[NeMo I 2021-11-06 00:15:06 cloud:62] Re-using file from: /home/boris/.cache/torch/NeMo/NeMo_1.4.0/stt_en_citrinet_256_gamma_0_25/d6eff3868f2f7a4791eb935c8366fc46/stt_en_citrinet_256_gamma_0_25.nemo\n",
      "[NeMo I 2021-11-06 00:15:06 common:702] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2021-11-06 00:15:06 mixins:149] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-11-06 00:15:07 modelPT:131] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2021-11-06 00:15:07 modelPT:138] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    \n",
      "[NeMo W 2021-11-06 00:15:07 modelPT:144] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-11-06 00:15:07 features:262] PADDING: 16\n",
      "[NeMo I 2021-11-06 00:15:07 features:279] STFT using torch\n",
      "[NeMo I 2021-11-06 00:15:08 save_restore_connector:143] Model EncDecCTCModelBPE was successfully restored from /home/boris/.cache/torch/NeMo/NeMo_1.4.0/stt_en_citrinet_256_gamma_0_25/d6eff3868f2f7a4791eb935c8366fc46/stt_en_citrinet_256_gamma_0_25.nemo.\n",
      "[NeMo I 2021-11-06 00:15:08 mixins:149] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2021-11-06 00:15:09 collections:173] Dataset loaded with 10480 files totalling 19.11 hours\n",
      "[NeMo I 2021-11-06 00:15:09 collections:174] 0 files were filtered totalling 0.00 hours\n",
      "[NeMo I 2021-11-06 00:15:09 collections:173] Dataset loaded with 2620 files totalling 4.81 hours\n",
      "[NeMo I 2021-11-06 00:15:09 collections:174] 0 files were filtered totalling 0.00 hours\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2021-11-06 00:15:09 ctc_bpe_models:235] Could not load dataset as `manifest_filepath` was None. Provided config : {'manifest_filepath': None, 'sample_rate': 16000, 'batch_size': 4, 'shuffle': False, 'use_start_end_token': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-11-06 00:15:09 features:262] PADDING: 16\n",
      "[NeMo I 2021-11-06 00:15:09 features:279] STFT using torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2021-11-06 00:15:09 modelPT:544] Optimizer config = Novograd (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: [0.8, 0.25]\n",
      "        eps: 1e-08\n",
      "        grad_averaging: False\n",
      "        lr: 0.01\n",
      "        weight_decay: 0.001\n",
      "    )\n",
      "[NeMo I 2021-11-06 00:15:09 lr_scheduler:625] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7f65a64d5a50>\" \n",
      "    will be used during training (effective maximum steps = 10) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 1000\n",
      "    warmup_ratio: null\n",
      "    min_lr: 1.0e-05\n",
      "    last_epoch: -1\n",
      "    max_steps: 10\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name              | Type                              | Params\n",
      "------------------------------------------------------------------------\n",
      "0 | preprocessor      | AudioToMelSpectrogramPreprocessor | 0     \n",
      "1 | encoder           | ConvASREncoder                    | 9.1 M \n",
      "2 | decoder           | ConvASRDecoder                    | 657 K \n",
      "3 | loss              | CTCLoss                           | 0     \n",
      "4 | spec_augmentation | SpectrogramAugmentation           | 0     \n",
      "5 | _wer              | WERBPE                            | 0     \n",
      "------------------------------------------------------------------------\n",
      "9.8 M     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 M     Total params\n",
      "39.145    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd59944c6c247519bf052621ab5088b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "callback = PrintTableMetricsCallback()\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_steps=10,\\\n",
    "                     precision=32, sync_batchnorm=False,\\\n",
    "                     benchmark=False\n",
    "                    )\n",
    "\n",
    "model_name = 'stt_en_citrinet_256_gamma_0_25'\n",
    "freeze_encoder = False\n",
    "\n",
    "# Load pretrained checkpoint\n",
    "checkpoint = nemo_asr.models.EncDecCTCModelBPE.from_pretrained(\n",
    "    model_name\n",
    ") \n",
    "\n",
    "# Preserve the models decoder weights\n",
    "decoder_ckpt_copy = checkpoint.decoder.state_dict()\n",
    "\n",
    "# Load finetuning model\n",
    "asr_model = nemo_asr.models.EncDecCTCModelBPE(cfg=DictConfig(config), trainer=trainer)\n",
    "\n",
    "# Load up weights or not\n",
    "load_weights = False\n",
    "if load_weights:\n",
    "    # this allows decoder weights to be loaded if same shape as original citrinet (1024 subword encodings)\n",
    "    asr_model.load_state_dict(checkpoint.state_dict(), strict=False)\n",
    "\n",
    "    # Insert preserved model weights if shapes match\n",
    "    if decoder_ckpt_copy['decoder_layers.0.weight'].shape == asr_model.decoder.decoder_layers[0].weight.shape:\n",
    "        asr_model.decoder.load_state_dict(decoder_ckpt_copy)\n",
    "\n",
    "# # release checkpoint memory\n",
    "del checkpoint\n",
    "\n",
    "# If freezing the encoder, unfreeze the batch norm and the squeeze and excite blocks\n",
    "# for transfer learning\n",
    "if freeze_encoder:\n",
    "    asr_model.encoder.freeze()\n",
    "    asr_model.encoder.apply(enable_bn_se)\n",
    "\n",
    "# Train model\n",
    "trainer.fit(asr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Novograd (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: [0.8, 0.25]\n",
       "     eps: 1e-08\n",
       "     grad_averaging: False\n",
       "     initial_lr: 0.01\n",
       "     lr: 9.99000999000999e-06\n",
       "     weight_decay: 0.001\n",
       " )]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
